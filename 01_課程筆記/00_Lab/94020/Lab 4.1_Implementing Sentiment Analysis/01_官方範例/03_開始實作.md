# Lab 4.1

_å¯¦ä½œ_

<br>

## æº–å‚™å·¥ä½œ

_ç·¨è¼¯è…³æœ¬_

<br>

1. è¼‰å…¥ç’°å¢ƒè®Šæ•¸ï¼›æ¯æ¬¡é‡æ–°å¯¦ä½œéƒ½è¦é‡å•Ÿæ ¸å¿ƒè¼‰å…¥ç’°å¢ƒè®Šæ•¸ã€‚

    ```python
    from dotenv import load_dotenv
    import os

    # è¼‰å…¥ .env æ–‡ä»¶
    load_dotenv()
    ```

    ![](images/img_13.png)

<br>

2. é©—è­‰å¸³è™Ÿï¼Œå‹™å¿…ç¢ºèªè¼¸å‡ºçš„å¸³è™Ÿèˆ‡ Lab å–å¾—ç›¸åŒï¼Œè—‰æ­¤é©—è­‰ `.env` è¨­ç½®æ­£ç¢ºã€‚

    ```python
    import boto3

    # åˆå§‹åŒ– STS å®¢æˆ¶ç«¯
    sts_client = boto3.client('sts')

    # ç²å–ç•¶å‰å¸³æˆ¶çš„ Account ID
    account_id = sts_client.get_caller_identity()["Account"]
    print("ç•¶å‰çš„ Account ID:", account_id)
    ```

    ![](images/img_14.png)

<br>

## åœ¨æœ¬åœ°é‹ä½œ Sagemaker

_ç‰¹åˆ¥æ³¨æ„ï¼Œåœ¨æœ¬åœ°é‹è¡Œ `Sagemaker` æœƒæœ‰è«¸å¤šé™åˆ¶ï¼Œä»¥ä¸‹æœƒè©¦åœ–ç¹éé™åˆ¶ä¾†é€²è¡Œé‹ä½œã€‚_

<br>

1. å°å…¥ `sagemaker` èˆ‡ `Lab` æ“ä½œæœ‰é—œçš„åº«ï¼›å¾è¼¸å‡ºçš„è¨Šæ¯å¯çŸ¥ï¼Œ `SDK` æ²’æœ‰å¾é€™äº›ä½ç½®æ‡‰ç”¨é è¨­é…ç½®ï¼Œä½†é€™ä¸å½±éŸ¿ `SDK` çš„æ­£å¸¸é‹è¡Œï¼Œå¯ä»¥å¿½ç•¥é€™äº›è³‡è¨Šï¼›ç‰¹åˆ¥æ³¨æ„ï¼Œé€™åœ¨ Lab é‹è¡Œä¹Ÿæœƒé¡¯ç¤ºç›¸åŒè¨Šæ¯ã€‚

    ```python
    import sagemaker
    from sagemaker.estimator import Estimator
    from sagemaker import get_execution_role
    ```

    ![](images/img_15.png)

<br>

## æŒ‡å®šè§’è‰²

1. åœ¨é›²ç«¯é‹ä½œæ™‚ï¼Œå¯ç›´æ¥æŒ‡å®šè§’è‰²ï¼Œå°‡ä»¥ä¸‹ä»£ç¢¼æ›¿ç‚ºæŒ‡å®šè§’è‰²ä¸¦å¯«åœ¨ CELL ä¸­å³å¯ã€‚

    ```python
    role = "<arn:aws:iam::XX-å…±12ç¢¼-XXX:role/è‡ªå·±çš„-SageMaker-åŸ·è¡Œè§’è‰²>"
    ```

<br>

2. åŸºæ–¼è‡ªå‹•åŒ–çš„è€ƒé‡ï¼Œåœ¨é›²ç«¯å¯é€éå‡½æ•¸å–å¾—è§’è‰²ä¸¦å­˜å…¥è®Šæ•¸ä¸­ï¼›ç‰¹åˆ¥æ³¨æ„ï¼Œé€™åªåœ¨é›²ç«¯ SageMaker notebook ç’°å¢ƒä¸­é©ç”¨ï¼Œæœ¬åœ°èª¿ç”¨é€™å€‹å‡½æ•¸å¾—åˆ°çš„æœƒæ˜¯ Lab è§’è‰²ï¼Œè€Œä¸æ˜¯é‡å° SageMaker è³¦äºˆçš„è§’è‰²ã€‚

    ```python
    role = get_execution_role()
    role
    ```

<br>

3. åœ¨æœ¬åœ°é‹è¡Œæœƒé¡¯ç¤ºè­¦å‘Šï¼Œé›–ç„¶ä¾èˆŠè¿”å›è§’è‰²çš„ ARNï¼Œä½†é€™ä¸¦é Lab è³¦äºˆæ¬Šé™çš„ Roleï¼›æ›å¥è©±èªªï¼Œç•¶å‰å–å¾—çš„è§’è‰²ä¸¦éé‹è¡Œæœ¬è¡Œæ¡ˆæ‰€è™›è¦çš„ï¼Œä¹‹å¾Œæœƒå¦åšè™•ç†ï¼Œé€™è£¡å…ˆèªªæ˜é€™å€‹ç‹€æ³ã€‚

    ```bash
    role_local = get_execution_role()
    role_local
    ```

    ![](images/img_16.png)

<br>

## æŸ¥è©¢ä¸¦å–å¾—è¨­ç½®

_S3 Bucketã€IAM Roles_

<br>

1. å–å¾—åç¨±ä¸­åŒ…å« `labbucket` çš„ S3 bucketï¼Œä¸¦å­˜å…¥è®Šæ•¸ `bucket_name` ä¸­ï¼Œé€™å°‡æ‡‰ç”¨æ–¼å¾ŒçºŒçš„ä»£ç¢¼ä¸­ï¼›ç‰¹åˆ¥æ³¨æ„ï¼Œå› ç‚ºå®˜æ–¹ç¯„ä¾‹ä½¿ç”¨çš„è®Šæ•¸åç¨±æ˜¯ `bucket`ï¼Œé€™è£¡åŒæ™‚ä¿ç•™äº† `bucket_name` ä¸¦å­˜å…¥ `bucket`ï¼Œä¸€æ–¹é¢æ˜¯å°æ‡‰å®˜æ–¹ç¯„ä¾‹ï¼ŒäºŒæ–¹é¢æ˜¯é¿å…éŒ¯èª¤è¦†è“‹æ™‚å¯é€²è¡Œæ¢å¾©ã€‚

    ```python
    import boto3

    # åˆå§‹åŒ– S3 å®¢æˆ¶ç«¯
    s3_client = boto3.client('s3')

    # åˆ—å‡ºæ‰€æœ‰ S3 buckets ä¸¦ç¯©é¸åç¨±åŒ…å« 'labbucket' çš„
    try:
        response = s3_client.list_buckets()
        # åªå–å‡ºç¬¬ä¸€å€‹åç¨±åŒ…å« 'labbucket' çš„ S3 bucketï¼Œè‹¥ç„¡å‰‡è¿”å› None
        bucket_name = next((bucket['Name'] for bucket in response['Buckets'] if 'labbucket' in bucket['Name']), None)

        # é¡¯ç¤ºçµæœ
        if bucket_name:
            print("åŒ…å« 'labbucket' çš„ S3 Bucketï¼š", bucket_name)
        else:
            print("æ‰¾ä¸åˆ°åŒ…å« 'labbucket' çš„ S3 Bucketã€‚")
    except Exception as e:
        print(f"ç™¼ç”ŸéŒ¯èª¤: {e}")

    # é…åˆå®˜æ–¹ç¯„ä¾‹ï¼Œå°‡å‘½åç‚º `bucket`
    bucket = bucket_name
    bucket
    ```

    ![](images/img_17.png)

<br>

2. é—œæ–¼é€™å€‹ Bucketï¼Œå¯é€²å…¥ S3 ä¸»æ§å°æŸ¥çœ‹ã€‚

    ![](images/img_50.png)

<br>

3. æª¢æŸ¥æŒ‡å®š Bucket ä¸­æ˜¯å¦æœ‰è³‡æ–™å¤¾æˆ–æ–‡ä»¶ã€‚

    ```python
    def list_s3_structure(bucket_name, prefix='', level=0):
        s3_client = boto3.client('s3')
        result = s3_client.list_objects_v2(
            Bucket=bucket_name, Prefix=prefix, Delimiter='/'
        )
        # æ ¹æ“šå±¤ç´šç¸®é€²
        indent = '    ' * level
        has_content = False

        # åˆ—å‡ºè³‡æ–™å¤¾
        if 'CommonPrefixes' in result:
            has_content = True
            for folder in result['CommonPrefixes']:
                # é¡¯ç¤ºè³‡æ–™å¤¾åç¨±
                print(
                    f"{indent}ğŸ“ {folder['Prefix'].split('/')[-2]}"
                )
                # éæ­¸åˆ—å‡ºå­è³‡æ–™å¤¾
                list_s3_structure(
                    bucket_name, 
                    prefix=folder['Prefix'], 
                    level=level + 1
                )

        # åˆ—å‡ºæ–‡ä»¶
        if 'Contents' in result:
            has_content = True
            for file in result['Contents']:
                # é¿å…é‡è¤‡é¡¯ç¤ºè³‡æ–™å¤¾çš„ key
                if file['Key'] != prefix:
                    # é¡¯ç¤ºæ–‡ä»¶åç¨±
                    print(f"{indent}ğŸ“„ {file['Key'].split('/')[-1]}")

        # å¦‚æœæ²’æœ‰å…§å®¹ï¼Œå‰‡è¼¸å‡ºé€šçŸ¥
        if not has_content and level == 0:
            print(f"Bucket '{bucket_name}' ä¸­æ²’æœ‰ä»»ä½•å…§å®¹ã€‚")

    # èª¿ç”¨
    list_s3_structure(bucket_name)
    ```

    ![](images/img_57.png)

<br>

4. æŸ¥è©¢æœ‰å“ªäº› Rolesï¼Œå‰é¢æ­¥é©Ÿæ›¾å–å¾—çš„å°±æ˜¯å…¶ä¸­çš„ `voclabs`ã€‚

    ```python
    # åˆå§‹åŒ– IAM å®¢æˆ¶ç«¯
    iam_client = boto3.client('iam')

    # åˆ—å‡ºæ‰€æœ‰ IAM è§’è‰²çš„åç¨±
    try:
        roles = iam_client.list_roles()
        print("å¸³æˆ¶ä¸­çš„ IAM è§’è‰²åç¨±ï¼š")
        for role in roles['Roles']:
            print(role['RoleName'])
    except Exception as e:
        print(f"ç™¼ç”ŸéŒ¯èª¤: {e}")
    ```

    ![](images/img_18.png)

<br>

5. åŒæ¨£åœ¨ IAM ä¸»æ§å°ä¸­ä¹Ÿå¯æŸ¥çœ‹åˆ°é€™äº› Rolesã€‚

    ![](images/img_51.png)

<br>

## å°å…¥ä¸»è¦åº«

1. å°å…¥åº«ä¸¦ä¸‹è¼‰ NLTKã€‚

    ```python
    # æ–‡ä»¶ã€è¼¸å…¥è¼¸å‡ºå’Œæ•¸æ“šçµæ§‹
    import os, io, struct
    import numpy as np
    import pandas as pd
    from sklearn.metrics import (
        # è¨ˆç®— ROC AUC åˆ†æ•¸
        roc_auc_score,
        # è¨ˆç®— ROC æ›²ç·šçš„åº§æ¨™
        roc_curve,
        # è¨ˆç®— AUC å€¼
        auc,
        # è¨ˆç®—æ··æ·†çŸ©é™£
        confusion_matrix
    )
    # ç”¨æ–¼æ•¸æ“šè¦–è¦ºåŒ–çš„åº«
    import seaborn as sns
    import matplotlib.pyplot as plt
    # ç”¨æ–¼è™•ç†æ—¥æœŸå’Œæ™‚é–“çš„åº«
    from datetime import datetime

    # åŒ¯å…¥ NLTK åº«ä»¥é€²è¡Œè‡ªç„¶èªè¨€è™•ç†
    import nltk

    '''ä¸‹è¼‰ NLTK è³‡æ–™é›†'''
    # ä¸‹è¼‰å¥å­åˆ†å‰²æ‰€éœ€çš„è³‡æ–™é›†
    nltk.download('punkt')
    # ä¸‹è¼‰åœç”¨è©åˆ—è¡¨
    nltk.download('stopwords')
    # ä¸‹è¼‰è©æ€§æ¨™è¨»å™¨
    nltk.download('averaged_perceptron_tagger')
    # ä¸‹è¼‰ WordNet è©å…¸
    nltk.download('wordnet')
    ```

    ![](images/img_01.png)

<br>

2. å¯é€²å…¥æª”æ¡ˆç³»çµ±ä¸­æŸ¥çœ‹ï¼Œä½ç½®åœ¨ `~/nltk_data`ï¼›`corpora` ä¸­å­˜æ”¾å„ç¨®èªæ–™åº«ï¼Œä¹Ÿå°±æ˜¯å¤§é‡çš„æ–‡æœ¬æ•¸æ“šé›†ï¼›`sentiment` å­˜æ”¾èˆ‡æƒ…æ„Ÿåˆ†æç›¸é—œçš„æ¨¡å‹æˆ–è³‡æ–™é›†ï¼›`taggers` åŒ…å«å„ç¨®æ¨™è¨»å™¨æ¨¡å‹ï¼Œä¾‹å¦‚è©æ€§æ¨™è¨»å™¨ï¼›`tokenizers` åŒ…å«å„ç¨®åˆ†è©å™¨ï¼Œé€™äº›å·¥å…·å¯å°‡æ–‡æœ¬åˆ‡åˆ†ç‚ºè©å½™æˆ–å¥å­ã€‚

    ![](images/img_52.png)

<br>

## è‡ªè¨‚è¼”åŠ©å‡½æ•¸

_é€™åœ¨ä¹‹å¾Œæœƒèª¿ç”¨_

<br>

1. ç¹ªè£½æ··æ·†çŸ©é™£çš„ç†±åŠ›åœ–ã€‚

    ```python
    def plot_confusion_matrix(test_labels, target_predicted):
        # è¨ˆç®—æ··æ·†çŸ©é™£
        matrix = confusion_matrix(test_labels, target_predicted)
        # å°‡æ··æ·†çŸ©é™£è½‰æ›ç‚º DataFrame æ ¼å¼
        df_confusion = pd.DataFrame(matrix)
        # è¨­å®šé¡è‰²åœ–çš„é…è‰²æ–¹æ¡ˆ
        colormap = sns.color_palette("BrBG", 10)
        # ç¹ªè£½ç†±åŠ›åœ–ï¼Œä¸¦é¡¯ç¤ºæ•¸å€¼
        sns.heatmap(df_confusion, annot=True, fmt='.2f', cbar=None, cmap=colormap)
        # è¨­å®šåœ–è¡¨çš„æ¨™é¡Œ
        plt.title("Confusion Matrix")
        # è‡ªå‹•èª¿æ•´ä½ˆå±€
        plt.tight_layout()
        # è¨­å®š y è»¸æ¨™ç±¤ç‚º "True Class"ï¼ˆçœŸå¯¦é¡åˆ¥ï¼‰
        plt.ylabel("True Class")
        # è¨­å®š x è»¸æ¨™ç±¤ç‚º "Predicted Class"ï¼ˆé æ¸¬é¡åˆ¥ï¼‰
        plt.xlabel("Predicted Class")
        # é¡¯ç¤ºåœ–è¡¨
        plt.show()
    ```

<br>

2. è¨ˆç®—å’Œè¼¸å‡ºæ¨¡å‹çš„æ€§èƒ½æŒ‡æ¨™ã€‚

    ```python
    def print_metrics(test_labels, target_predicted_binary):
        # è¨ˆç®—æ··æ·†çŸ©é™£ä¸¦è§£å£“ç¸®æˆ TN, FP, FN, TP
        TN, FP, FN, TP = confusion_matrix(test_labels, target_predicted_binary).ravel()
        # è¨ˆç®—éˆæ•åº¦ã€å‘½ä¸­ç‡ã€å¬å›ç‡æˆ–çœŸé™½æ€§ç‡
        Sensitivity = float(TP)/(TP+FN)*100
        # è¨ˆç®—ç‰¹ç•°æ€§æˆ–çœŸé™°æ€§ç‡
        Specificity = float(TN)/(TN+FP)*100
        # è¨ˆç®—ç²¾ç¢ºåº¦æˆ–æ­£é™½æ€§é æ¸¬å€¼
        Precision = float(TP)/(TP+FP)*100
        # è¨ˆç®—é™°æ€§é æ¸¬å€¼
        NPV = float(TN)/(TN+FN)*100
        # è¨ˆç®—éŒ¯èª¤ç‡æˆ–å‡é™½æ€§ç‡
        FPR = float(FP)/(FP+TN)*100
        # è¨ˆç®—å‡é™°æ€§ç‡
        FNR = float(FN)/(TP+FN)*100
        # è¨ˆç®—éŒ¯èª¤ç™¼ç¾ç‡
        FDR = float(FP)/(TP+FP)*100
        # è¨ˆç®—æ•´é«”æº–ç¢ºç‡
        ACC = float(TP+TN)/(TP+FP+FN+TN)*100

        '''å€‹ç›¸è¼¸å‡º'''
        # éˆæ•åº¦æˆ– TPR
        print(f"Sensitivity or TPR: {Sensitivity}%")    
        # ç‰¹ç•°æ€§æˆ– TNR
        print(f"Specificity or TNR: {Specificity}%") 
        # ç²¾ç¢ºåº¦
        print(f"Precision: {Precision}%")   
        # é™°æ€§é æ¸¬å€¼
        print(f"Negative Predictive Value: {NPV}%")  
        # å‡é™½æ€§ç‡
        print(f"False Positive Rate: {FPR}%") 
        # å‡é™°æ€§ç‡
        print(f"False Negative Rate: {FNR}%")  
        # éŒ¯èª¤ç™¼ç¾ç‡
        print(f"False Discovery Rate: {FDR}%" )
        # æ•´é«”æº–ç¢ºç‡
        print(f"Accuracy: {ACC}%")
    ```

<br>

## æ‰‹å‹•ä¸‹è¼‰æ•¸æ“šé›†

_IMDB çš„æ•¸æ“šé›†ä¸¦éä»¥ `imdb.csv` çš„å½¢å¼ç›´æ¥æä¾›ï¼Œå®˜æ–¹ç¯„ä¾‹æ˜¯ç›´æ¥é å…ˆæº–å‚™å¥½çš„ï¼Œé€™è£¡æ‰‹å‹•é€²è¡Œè¼‰ä¸¦åŠ ä»¥è™•ç†ã€‚_

<br>

1. ä¸‹è¼‰ä¸¦å°‡è³‡æ–™çµ„åˆè½‰æ›æˆ `CSV` æ ¼å¼ï¼›ç¨‹å¼ç¢¼ç”Ÿæˆçš„ `imdb.csv` åŒ…å«å…©åˆ— `review` å’Œ `sentiment`ï¼Œåˆ†åˆ¥è¨˜éŒ„ `è©•è«–æ–‡æœ¬` èˆ‡ `æ­£é¢æˆ–è² é¢çš„æ¨™è¨˜`ï¼Œé€™æ¨£çš„æ ¼å¼å¯ç”¨æ–¼æƒ…ç·’åˆ†æä»»å‹™ï¼›ç‰¹åˆ¥æ³¨æ„ï¼Œæ‰‹å‹•ä¸‹è¼‰å¾Œçš„åŸå§‹æ•¸æ“šé›†åœ¨æ¬„ä½åç¨±ä¸Šèˆ‡ Lab æä¾›çš„ä¸åŒï¼Œé€™åœ¨å¾ŒçºŒæ­¥é©Ÿæœƒé€²è¡Œè½‰æ›ã€‚

    ```python
    import urllib.request
    import tarfile

    # å®šç¾©ä¸‹è¼‰ URL å’Œè³‡æ–™å¤¾åç¨±
    url = "http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz"
    data_dir = "aclImdb"

    # ä¸‹è¼‰ IMDB è³‡æ–™é›†
    if not os.path.exists("aclImdb_v1.tar.gz"):
        print("Downloading IMDB dataset...")
        urllib.request.urlretrieve(url, "aclImdb_v1.tar.gz")
        print("Download complete.")

    # è§£å£“ç¸®è³‡æ–™é›†
    if not os.path.exists(data_dir):
        print("Extracting IMDB dataset...")
        with tarfile.open("aclImdb_v1.tar.gz", "r:gz") as tar_ref:
            tar_ref.extractall(".")
        print("Extraction complete.")

    # æº–å‚™è³‡æ–™ä¸¦è½‰æ›ç‚º CSV æ ¼å¼
    data = {"review": [], "sentiment": []}

    # è®€å–è³‡æ–™å¤¾ä¸­çš„æª”æ¡ˆä¸¦æ¨™è¨˜æ­£é¢/è² é¢
    for split in ["train", "test"]:
        for sentiment in ["pos", "neg"]:
            folder_path = os.path.join(data_dir, split, sentiment)
            # æª¢æŸ¥è³‡æ–™å¤¾æ˜¯å¦å­˜åœ¨
            if os.path.exists(folder_path):
                for filename in os.listdir(folder_path):
                    file_path = os.path.join(folder_path, filename)
                    with open(file_path, "r", encoding="utf-8") as file:
                        review = file.read()
                        # æ­£é¢ç‚º 1ï¼Œè² é¢ç‚º 0
                        label = 1 if sentiment == "pos" else 0 
                        data["review"].append(review)
                        data["sentiment"].append(label)

    # è½‰æ›ç‚º DataFrame ä¸¦å­˜æˆ CSV
    df = pd.DataFrame(data)
    df.to_csv("imdb.csv", index=False)
    print("CSV file 'imdb.csv' created successfully.")
    ```

    ![](images/img_02.png)

<br>

2. åœ¨æœ¬åœ°å°ˆæ¡ˆè·¯å¾‘ä¸­å¯çœ‹åˆ°æ·»åŠ ä¸€å€‹ç›®éŒ„ã€ä¸‰å€‹æ–‡ä»¶ï¼Œå…¶ä¸­ `imdb.csv` ä¾¿æ˜¯ç¶“éè½‰æ›å¾Œçš„æ–°è³‡æ–™é›†ï¼›ç‰¹åˆ¥æ³¨æ„ï¼Œåœ¨é›²ç«¯ç’°å¢ƒä¸­ï¼Œè³‡æ–™é›†è¢«å­˜æ”¾åœ¨ `'../data/imdb.csv'` è·¯å¾‘ä¸­ã€‚

    ![](images/img_19.png)

<br>

## è®€å–æ•¸æ“šé›†

1. è®€å–ä¸¦é¡¯ç¤ºè³‡æ–™ï¼›ç‰¹åˆ¥æ³¨æ„ï¼Œåœ¨é€™è£¡å·²ç¶“å°‡æ•¸æ“šå­˜å…¥ `df`ï¼Œè³‡æ–™è¡¨æœ‰å…©å€‹æ¬„ä½ï¼Œåˆ†åˆ¥æ˜¯ `review` åŠ `sentiment`ã€‚

    ```python
    df = pd.read_csv('imdb.csv', header=0)
    df
    ```

    ![](images/img_03.png)

<br>

## å¿«é€Ÿé€²å…¥ Sagemaker

_ç”Ÿæˆé€£çµå¿«é€Ÿé€²å…¥ï¼Œä¸¦ä¸‹è¼‰ç¯„ä¾‹æ•¸æ“šé€²è¡Œæ¯”è¼ƒ_

<br>

1. å¯è‡ªå‹•åŒ–ç”Ÿæˆå®˜æ–¹ç¯„ä¾‹æ–‡ä»¶çš„é€£çµã€‚

    ```python
    # ç²å– SageMaker å®¢æˆ¶ç«¯
    sagemaker_client = boto3.client('sagemaker')

    # ç²å–æ‰€æœ‰ Notebook å¯¦ä¾‹
    notebook_instances = sagemaker_client.list_notebook_instances()

    # ç²å–ç•¶å‰ Notebook å¯¦ä¾‹åç¨±
    # å‡è¨­åªå­˜åœ¨ä¸€å€‹ Notebook å¯¦ä¾‹ï¼Œæ‚¨å¯ä»¥æ ¹æ“šéœ€è¦é€²è¡Œä¿®æ”¹
    notebook_instance_name = \
        notebook_instances['NotebookInstances'][0]['NotebookInstanceName']

    # è¨­å®š AWS å€åŸŸ
    aws_region = boto3.Session().region_name

    # è¨­å®šè·¯å¾‘å’Œæª”æ¡ˆåç¨±
    folder_path = 'data'
    file_name = 'imdb.csv'

    # è‡ªå‹•ç”Ÿæˆç¶²å€
    s3_url = \
        f"https://{notebook_instance_name}.notebook."\
        f"{aws_region}.sagemaker.aws/lab/tree/{folder_path}/{file_name}"

    # è¼¸å‡ºç”Ÿæˆçš„ URL
    print("ç”Ÿæˆçš„ CSV æ–‡ä»¶ç¶²å€:", s3_url)
    ```

    ![](images/img_47.png)

<br>

2. æ‰“é–‹é€£çµå¯å¿«é€Ÿé€²å…¥ Labï¼Œåœ¨æ•¸æ“šé›†é»æ“Šå³éµä¸‹è¼‰åˆ°æœ¬åœ°ã€‚

    ![](images/img_34.png)

<br>

3. ç‚ºäº†æ¯”å°å®˜æ–¹æ•¸æ“šèˆ‡è‡ªè¡Œä¸‹è¼‰æ•¸æ“šæ˜¯å¦å­˜åœ¨å·®ç•°ï¼Œæ¥è‘—å°‡ä¸‹è¼‰çš„æ–‡ä»¶æ›´åç‚º `imdb_0.csv` å¾Œæ‹–æ›³é€²å…¥å°ˆæ¡ˆè³‡æ–™å¤¾ä¸­ã€‚

    ![](images/img_24.png)

<br>

4. é€éä»£ç¢¼è§€å¯Ÿï¼Œçµæœé¡¯ç¤ºæ•¸æ“šçš„å…§å®¹èˆ‡æ¬„ä½ä¸ä¸€æ¨£ï¼Œä½†æ ¼å¼æ˜¯ç›¸åŒçš„ï¼Œä¸¦ä¸”è³‡æ–™ç­†æ•¸ `50,000` ä¹Ÿç›¸åŒã€‚

    ```python
    df_0 = pd.read_csv('imdb_0.csv', header=0)
    df_0
    ```

    ![](images/img_04.png)

<br>

5. åˆ—å‡ºå…©å€‹æ•¸æ“šçš„æ¬„ä½åç¨±ï¼Œçµæœé¡¯ç¤ºå®˜æ–¹æ•¸æ“šé›†çš„æ¬„ä½åç¨±æ˜¯ `text` å’Œ `label`ï¼Œè€Œä¸‹è¼‰æ•¸æ“šé›†çš„æ¬„ä½æ˜¯ `review`ã€`sentiment`ã€‚

    ```python
    print(df.head())
    print(df_0.head())
    ```

    ![](images/img_05.png)

<br>

6. å°‡ä¸‹è¼‰æ•¸æ“šé›† `imdb.csv` çš„æ¬„ä½åç¨±ä¿®æ”¹èˆ‡å®˜æ–¹è³‡æ–™é›†ä¸€è‡´ã€‚

    ```python
    # å°‡æ¬„ä½åç¨±é‡å‘½åç‚ºå®˜æ–¹æ ¼å¼
    df.rename(
        columns={"review": "text", "sentiment": "label"},
        inplace=True
    )

    # å°‡æ›´æ”¹å¾Œçš„ DataFrame å„²å­˜å› CSV
    df.to_csv("imdb.csv", index=False)

    print("æ¬„ä½åç¨±å·²ä¿®æ”¹ç‚ºèˆ‡å®˜æ–¹ä¸€è‡´ï¼Œä¸¦é‡æ–°å„²å­˜ç‚º 'imdb.csv'ã€‚")

    # é‡æ–°è®€å–æ›´æ–°å¾Œçš„æ–‡ä»¶
    df = pd.read_csv("imdb.csv")
    print("é‡æ–°è®€å–å¾Œçš„æ¬„ä½åç¨±ï¼š", df.columns.tolist())
    ```

    ![](images/img_20.png)

<br>

7. æ¯”å°æ•¸æ“šï¼Œæå–è‡ªè¡Œä¸‹è¼‰çš„æ•¸æ“šé›†å‰äº”ç­†é€²è¡ŒæŸ¥è©¢ï¼Œæ¯”å°è©²ç­†æ•¸æ“šæ˜¯å¦å­˜åœ¨æ–¼å®˜æ–¹è³‡æ–™é›†ä¸­ï¼Œä¸¦æ˜ç¢ºæŒ‡å‡ºæ˜¯è³‡æ–™é›†çš„å“ªä¸€ç­†ï¼›æ­¤æ­¥é©Ÿç”¨å·²ç¢ºèªæ˜¯å¦åƒ…åƒ…æ˜¯æ’åºå•é¡Œã€‚

    ```python
    # é‡æ–°è®€å–æ›´æ–°å¾Œçš„æ•¸æ“šé›†
    df = pd.read_csv("imdb.csv")

    # å–å‡ºè‡ªè¡Œä¸‹è¼‰çš„æ•¸æ“šé›†å‰äº”ç­†è³‡æ–™
    first_five_rows = df.head(5)

    # å»ºç«‹ä¸€å€‹ç©ºçš„åˆ—è¡¨ä¾†å„²å­˜åŒ¹é…çµæœ
    matches = []

    # éæ­·å‰äº”ç­†è³‡æ–™ï¼Œé€ç­†èˆ‡å®˜æ–¹æ•¸æ“šé›†æ¯”å°
    for index, row in first_five_rows.iterrows():
        match = df_0[
            (df_0['text'] == row['text']) & 
            (df_0['label'] == row['label'])
        ]
        # å¦‚æœåŒ¹é…åˆ°æ•¸æ“šï¼Œå°‡çµæœåŠ å…¥åˆ—è¡¨
        if not match.empty:
            matches.append(match)

    # é¡¯ç¤ºåŒ¹é…çš„åˆ—
    if matches:
        matched_df = pd.concat(matches)
        print("å‰äº”ç­†æ•¸æ“šåœ¨å®˜æ–¹æ•¸æ“šé›†ä¸­çš„åˆ—ï¼š")
        print(matched_df)
    else:
        print("åœ¨å®˜æ–¹æ•¸æ“šé›†ä¸­æ‰¾ä¸åˆ°èˆ‡å‰äº”ç­†è³‡æ–™åŒ¹é…çš„åˆ—ã€‚")
    ```

    ![](images/img_06.png)

<br>

## æ¢ç´¢æ•¸æ“š

_ä»¥ä¸‹æ˜¯å®˜æ–¹ç¯„ä¾‹ä¸­æ¢ç´¢æ•¸æ“šçš„ä»£ç¢¼ï¼Œå¯é‹è¡Œæ“ä½œã€‚_

<br>

1. æŸ¥çœ‹å‰é¢ `8` ç­†ã€‚

    ```python
    def show_eight_rows(df):
        return df.head(8)    

    print(show_eight_rows(df))
    ```

    ![](images/img_07.png)

<br>

2. æŸ¥çœ‹æ•¸æ“šçµæ§‹ã€‚

    ```python
    def show_data_shape(df):
        return df.shape

    print(show_data_shape(df))
    ```

    ![](images/img_08.png)

<br>

3. è³‡æ–™ä¸­æ­£é¢å’Œè² é¢å¯¦ä¾‹æ•¸é‡ï¼›å¯è‡ªè¡Œæ›¿æ›æ–‡ä»¶åç¨±ä¾†æŸ¥çœ‹ç¯„ä¾‹æ–‡ä»¶çš„å…§å®¹ã€‚

    ```python
    def show_data_instances(df):
        return df['label'].value_counts()

    print(show_data_instances(df))
    ```

    ![](images/img_09.png)

<br>

4. æª¢æŸ¥éºæ¼ç¼ºå¤±å€¼ã€‚

    ```python
    def show_missing_values(df):
        return df.isna().sum()
        

    print(show_missing_values(df))
    ```

    ![](images/img_10.png)

<br>

___

_ç¹¼çºŒä¸‹ä¸€éšæ®µ_