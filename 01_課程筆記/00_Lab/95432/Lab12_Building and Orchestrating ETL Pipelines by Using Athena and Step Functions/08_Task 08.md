# Task 8：使用分區進行數據優化

此任務的目標是創建一個 `yellowtaxi_data_parquet` 表，並採用 Parquet 格式和 Snappy 壓縮技術，與之前對 lookup 表所做的操作類似。此外，將針對出租車數據進行分區，因為該數據具有時間特性，分區可以根據時間更好地組織數據。

通過在 Amazon S3 中創建一個名為 `optimized-data` 的前綴，可以通過提取年份和月份來進行分區。分區的好處是可以限制每次查詢掃描的數據量，從而提升性能並降低成本。分區將表格分為不同部分，並根據欄位值將相關數據放在一起。

藉由分區，當新數據加入時，會根據時間分段儲存，這樣包含取車日期的查詢將更加高效。與 Parquet 格式和 Snappy 壓縮技術配合使用，數據存儲將得到全面優化。

## 更新工作流以創建具分區功能的 Parquet 表

1. 在 `Step Functions` 主控台中，使用與之前步驟相同的方法開啟 `WorkflowPOC` 狀態機，進入 `Workflow Studio`。

2. 在 `Actions` 面板中，搜尋 `athena`。

3. 將 `StartQueryExecution` 任務拖到 `Run Create Parquet lookup Table Query` 與 `End` 任務之間。

4. 選擇新加入的 `StartQueryExecution` 任務，將 `State name` 改為 `Run Create Parquet data Table Query`。

5. 將 `API Parameters` 的預設 JSON 代碼替換為以下內容，並將 `<FMI_1>` 和 `<FMI_2>` 替換為實際的 S3 Bucket 名稱。

    ```json
    {
        "QueryString": "CREATE table if not exists nyctaxidb.yellowtaxi_data_parquet WITH (format='PARQUET',parquet_compression='SNAPPY',partitioned_by=array['pickup_year','pickup_month'],external_location = 's3://<FMI_1>/nyctaxidata/optimized-data/') AS SELECT vendorid,tpep_pickup_datetime,tpep_dropoff_datetime,passenger_count,trip_distance,ratecodeid,store_and_fwd_flag,pulocationid,dolocationid,fare_amount,extra,mta_tax,tip_amount,tolls_amount,improvement_surcharge,total_amount,congestion_surcharge,payment_type,substr(\"tpep_pickup_datetime\",1,4) pickup_year, substr(\"tpep_pickup_datetime\",6,2) AS pickup_month FROM nyctaxidb.yellowtaxi_data_csv where substr(\"tpep_pickup_datetime\",1,4) = '2020' and substr(\"tpep_pickup_datetime\",6,2) = '01'",
        "WorkGroup": "primary",
        "ResultConfiguration": {
          "OutputLocation": "s3://<FMI_2>/athena/"
        }
    }
    ```

6. 選擇 `Wait for task to complete`（可選），以確保表完全創建後再進行下一步。

7. 點擊 `Save` 保存工作流。

## 測試並驗證結果

1. 在 `AWS Glue` 主控台中，刪除現有的三個表，這樣可以確保下次運行工作流時選擇正確的路徑。

2. 在 `S3` 主控台中，進入 `gluelab` 存儲桶的 `athena` 資料夾，找到 `nyctaxidata` 前綴。

3. 選擇 `optimized-data-lookup` 前綴，然後點擊 `Delete`。

4. 在刪除頁面底部輸入 `permanently delete`，然後選擇 `Delete objects`，完成後點擊 `Close`。

    > 解釋：由於賦予 Athena 的權限不允許它刪除存儲在 S3 的表信息，因此需要手動刪除 S3 存儲桶中的 `optimized-data-lookup` 前綴，否則工作流在運行 `Create Parquet lookup Table Query` 任務時將會失敗。這個問題只會出現在內部表（如 Parquet 表），而不是外部表。

5. 在 `Step Functions` 主控台中，使用與之前相同的方法運行 `WorkflowPOC` 狀態機，測試命名為 `TaskEightTest`。

    下圖顯示了成功完成的工作流。

    ![](images/task8_workflow_completed.png)

## 驗證新表的創建

1. 在 `Athena` 主控台的導航面板中，選擇 `Query editor`。

    > 提示：如果導航面板已經折疊，點擊菜單圖標打開它。

2. 選擇 `Settings` 頁籤，點擊 `Manage` 並配置如下：

    - 選擇 `Browse S3`。
    - 點擊 `gluelab` 存儲桶的鏈接。
    - 選擇 `athena` 前綴。
    - 點擊 `Choose`。
    - 點擊 `Save`。

3. 選擇 `Editor` 頁籤，進入 `Data` 面板，對於 `Database`，選擇 `nyctaxidb`。

4. 展開 `yellowtaxi_data_parquet` 表，確認表的結構，下圖顯示了展開後的表。

    ![](images/task8_parquet_table_schema.png)

5. 注意表的 `Partitioned` 標籤，您可能需要向下滾動以查看最後兩列，這些列是作為分區儲存的字符串。

---

至此，已成功在 AWS Glue 中重新創建兩個 Parquet 格式表，並使用 Snappy 壓縮技術。此外，還對 `yellowtaxi_data_parquet` 表進行了分區設置，並確認該表能夠在 Athena 查詢編輯器中加載。